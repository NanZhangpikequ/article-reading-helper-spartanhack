# -*- coding: utf-8 -*-
"""
åœ¨ HuggingFace midas/inspec (extraction) æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ª
ã€ŒBERT + TokenClassification (BIO æ ‡ç­¾)ã€çš„å°æ¨¡åž‹ï¼Œç”¨æ¥åšå…³é”®è¯æŠ½å–ã€‚

âš ï¸ ä¸ä½¿ç”¨ transformers.Trainerï¼Œæ”¹ä¸ºçº¯ PyTorch è®­ç»ƒå¾ªçŽ¯ï¼Œ
é¿å…å¯¼å…¥ transformers.data.metrics â†’ scipy é€ æˆçš„çŽ¯å¢ƒé—®é¢˜ã€‚
"""

import os
from typing import Dict, Any, List, Tuple

import torch
from torch.utils.data import DataLoader
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForTokenClassification
from tqdm import tqdm

from config import (
    BASE_MODEL_NAME,
    MODEL_DIR,
    MAX_SEQ_LEN,
    EPOCHS,
    TRAIN_BATCH_SIZE,
    EVAL_BATCH_SIZE,
    LEARNING_RATE,
    WEIGHT_DECAY,
)

# BIO æ ‡ç­¾é›†åˆ
LABEL_LIST = ["O", "B", "I"]
LABEL2ID = {l: i for i, l in enumerate(LABEL_LIST)}
ID2LABEL = {i: l for l, i in LABEL2ID.items()}

# å¯é€‰çš„ seqeval æŒ‡æ ‡
try:
    from seqeval.metrics import precision_score, recall_score, f1_score

    USE_SEQEVAL = True
except ImportError:
    USE_SEQEVAL = False
    print("âš ï¸ æ²¡æœ‰å®‰è£… seqevalï¼Œå°†ä¸åœ¨è®­ç»ƒä¸­è®¡ç®— F1ï¼ˆå¯ pip install seqevalï¼‰")


def load_inspec_extraction():
    """
    åŠ è½½ midas/inspec çš„ extraction é…ç½®ã€‚
    """
    dataset = load_dataset("midas/inspec", "extraction")
    return dataset["train"], dataset["validation"], dataset["test"]


def tokenize_and_align_labels(example: Dict[str, Any], tokenizer):
    """
    æŠŠ Inspec çš„ [word åˆ—è¡¨] + [BIO æ ‡ç­¾] è½¬æˆé€‚åˆ BERT çš„è¾“å…¥ï¼š
    - is_split_into_words=True
    - å¯¹ subword åªç»™ç¬¬ä¸€ä¸ª subword æ ‡æ³¨ï¼Œå…¶ä½™è®¾ä¸º -100ï¼ˆä¸ç®— lossï¼‰
    - ç›´æŽ¥ padding='max_length'ï¼Œè¿™æ · DataLoader å¯ä»¥ç”¨é»˜è®¤ collate_fn
    """
    words = example["document"]          # list[str]
    tags = example["doc_bio_tags"]       # list[str]ï¼Œå…ƒç´ æ˜¯ "B"/"I"/"O"

    encoding = tokenizer(
        words,
        is_split_into_words=True,
        truncation=True,
        max_length=MAX_SEQ_LEN,
        padding="max_length",
        return_offsets_mapping=False,
    )

    word_ids = encoding.word_ids()
    label_ids = []

    previous_word_id = None
    for word_id in word_ids:
        if word_id is None:
            label_ids.append(-100)
        elif word_id != previous_word_id:
            tag_str = tags[word_id]
            label_ids.append(LABEL2ID[tag_str])
        else:
            label_ids.append(-100)
        previous_word_id = word_id

    encoding["labels"] = label_ids
    return encoding


def prepare_datasets(tokenizer):
    """å¯¹æ•°æ®é›†åšé¢„å¤„ç†ï¼Œå¹¶è½¬æˆå¯ä»¥ç›´æŽ¥ç»™ DataLoader ç”¨çš„å½¢å¼ã€‚"""
    train_ds, val_ds, test_ds = load_inspec_extraction()

    def _preprocess(examples):
        return tokenize_and_align_labels(examples, tokenizer)

    encoded_train = train_ds.map(_preprocess, batched=False)
    encoded_val = val_ds.map(_preprocess, batched=False)
    encoded_test = test_ds.map(_preprocess, batched=False)

    # åŽ»æŽ‰åŽŸå§‹åˆ—ï¼Œåªä¿ç•™ input_ids, attention_mask, labels
    keep_cols = ["input_ids", "attention_mask", "labels"]
    encoded_train = encoded_train.remove_columns(
        [c for c in encoded_train.column_names if c not in keep_cols]
    )
    encoded_val = encoded_val.remove_columns(
        [c for c in encoded_val.column_names if c not in keep_cols]
    )
    encoded_test = encoded_test.remove_columns(
        [c for c in encoded_test.column_names if c not in keep_cols]
    )

    # è®© datasets è¿”å›ž torch.Tensor
    encoded_train.set_format(type="torch", columns=keep_cols)
    encoded_val.set_format(type="torch", columns=keep_cols)
    encoded_test.set_format(type="torch", columns=keep_cols)

    return encoded_train, encoded_val, encoded_test


def make_dataloaders(train_ds, val_ds, test_ds) -> Tuple[DataLoader, DataLoader, DataLoader]:
    train_loader = DataLoader(
        train_ds,
        batch_size=TRAIN_BATCH_SIZE,
        shuffle=True,
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=EVAL_BATCH_SIZE,
        shuffle=False,
    )
    test_loader = DataLoader(
        test_ds,
        batch_size=EVAL_BATCH_SIZE,
        shuffle=False,
    )
    return train_loader, val_loader, test_loader


def decode_preds_and_labels(
    logits: torch.Tensor,
    labels: torch.Tensor,
    id2label: Dict[int, str],
) -> Tuple[List[List[str]], List[List[str]]]:
    """
    æŠŠä¸€ä¸ª batch çš„ logits/labels è½¬æˆ seqeval éœ€è¦çš„æ ‡ç­¾åºåˆ—ã€‚
    """
    preds = logits.argmax(-1).cpu().numpy()
    labels = labels.cpu().numpy()

    batch_true = []
    batch_pred = []

    for pred_ids, label_ids in zip(preds, labels):
        true_tags = []
        pred_tags = []
        for p, l in zip(pred_ids, label_ids):
            if l == -100:
                continue
            true_tags.append(id2label[int(l)])
            pred_tags.append(id2label[int(p)])
        batch_true.append(true_tags)
        batch_pred.append(pred_tags)

    return batch_true, batch_pred


def evaluate(
    model,
    data_loader: DataLoader,
    device: torch.device,
    id2label: Dict[int, str],
) -> Dict[str, float]:
    """åœ¨ val/test ä¸Šè·‘ä¸€éï¼Œè¿”å›ž loss å’Œï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰F1 ç­‰æŒ‡æ ‡ã€‚"""
    model.eval()
    total_loss = 0.0
    total_steps = 0

    all_true: List[List[str]] = []
    all_pred: List[List[str]] = []

    with torch.no_grad():
        for batch in tqdm(data_loader, desc="Eval", leave=False):
            batch = {k: v.to(device) for k, v in batch.items()}
            outputs = model(
                input_ids=batch["input_ids"],
                attention_mask=batch["attention_mask"],
                labels=batch["labels"],
            )
            loss = outputs.loss
            total_loss += loss.item()
            total_steps += 1

            if USE_SEQEVAL:
                bt_true, bt_pred = decode_preds_and_labels(
                    outputs.logits, batch["labels"], id2label
                )
                all_true.extend(bt_true)
                all_pred.extend(bt_pred)

    avg_loss = total_loss / max(total_steps, 1)

    metrics = {"loss": avg_loss}
    if USE_SEQEVAL and all_true:
        p = precision_score(all_true, all_pred)
        r = recall_score(all_true, all_pred)
        f = f1_score(all_true, all_pred)
        metrics.update(
            {
                "precision": float(p),
                "recall": float(r),
                "f1": float(f),
            }
        )

    return metrics


def train():
    """
    åœ¨ Inspec æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶ä¿å­˜åˆ° MODEL_DIRã€‚
    """
    print("ðŸ“š Loading tokenizer and datasets...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)

    train_ds, val_ds, test_ds = prepare_datasets(tokenizer)
    print(f"Train size: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}")

    train_loader, val_loader, test_loader = make_dataloaders(
        train_ds, val_ds, test_ds
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("ðŸ–¥  Using device:", device)

    model = AutoModelForTokenClassification.from_pretrained(
        BASE_MODEL_NAME,
        num_labels=len(LABEL_LIST),
        id2label=ID2LABEL,
        label2id=LABEL2ID,
    ).to(device)

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY
    )

    best_f1 = -1.0
    os.makedirs(MODEL_DIR, exist_ok=True)

    for epoch in range(1, EPOCHS + 1):
        print(f"\n===== Epoch {epoch}/{EPOCHS} =====")
        # ------- è®­ç»ƒ -------
        model.train()
        total_loss = 0.0
        total_steps = 0

        for batch in tqdm(train_loader, desc="Train"):
            batch = {k: v.to(device) for k, v in batch.items()}
            outputs = model(
                input_ids=batch["input_ids"],
                attention_mask=batch["attention_mask"],
                labels=batch["labels"],
            )
            loss = outputs.loss

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            total_steps += 1

        avg_train_loss = total_loss / max(total_steps, 1)
        print(f"  Train loss: {avg_train_loss:.4f}")

        # ------- éªŒè¯ -------
        val_metrics = evaluate(model, val_loader, device, ID2LABEL)
        print(f"  Val loss: {val_metrics['loss']:.4f}")
        if USE_SEQEVAL and "f1" in val_metrics:
            print(
                f"  Val F1: {val_metrics['f1']:.4f}, "
                f"P: {val_metrics['precision']:.4f}, "
                f"R: {val_metrics['recall']:.4f}"
            )

            # ä¿å­˜æœ€å¥½çš„æ¨¡åž‹
            if val_metrics["f1"] > best_f1:
                best_f1 = val_metrics["f1"]
                print(f"  âœ… New best F1: {best_f1:.4f}, saving model to {MODEL_DIR}")
                model.save_pretrained(MODEL_DIR)
                tokenizer.save_pretrained(MODEL_DIR)
        else:
            # æ²¡æœ‰ seqeval å°±æŒ‰ loss å­˜ä¸€ä¸‹
            if best_f1 < 0 or val_metrics["loss"] < best_f1:
                best_f1 = val_metrics["loss"]
                print(f"  âœ… New best (by loss): {best_f1:.4f}, saving model to {MODEL_DIR}")
                model.save_pretrained(MODEL_DIR)
                tokenizer.save_pretrained(MODEL_DIR)

    # ------- åœ¨ test ä¸Šç®€å•è¯„ä¼°ä¸€ä¸‹ -------
    print("\nðŸ“Š Evaluating best model on test set...")
    # é‡æ–°åŠ è½½ä¿å­˜å¥½çš„ best æ¨¡åž‹ï¼ˆç¨³å¦¥ä¸€ç‚¹ï¼‰
    best_model = AutoModelForTokenClassification.from_pretrained(
        MODEL_DIR
    ).to(device)
    test_metrics = evaluate(best_model, test_loader, device, ID2LABEL)
    print("Test metrics:", test_metrics)

    print("\nâœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡åž‹ä¿å­˜åœ¨ï¼š", MODEL_DIR)


if __name__ == "__main__":
    if os.path.isdir(MODEL_DIR) and os.listdir(MODEL_DIR):
        print(f"æ¨¡åž‹ç›®å½• {MODEL_DIR} å·²å­˜åœ¨ï¼Œå¦‚éœ€é‡æ–°è®­ç»ƒè¯·å…ˆæ‰‹åŠ¨æ¸…ç©ºè¯¥ç›®å½•ã€‚")
    else:
        train()
